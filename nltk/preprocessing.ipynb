{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74BaeLIgH1IG"
      },
      "outputs": [],
      "source": [
        "# data_preprocessing.py\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def load_data(filepath):\n",
        "    \"\"\"Loads data from a CSV or JSON file.\"\"\"\n",
        "    try:\n",
        "      if filepath.endswith('.csv'):\n",
        "        return pd.read_csv(filepath)\n",
        "      elif filepath.endswith('.json'):\n",
        "        return pd.read_json(filepath)\n",
        "      else:\n",
        "          raise ValueError(\"Unsupported file type. Only CSV and JSON are supported\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error loading the file: {e}\")\n",
        "      return None\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Cleans text by removing special characters, punctuation, and numbers.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"  # Handle non-string inputs\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # remove urls\n",
        "    text = re.sub(r'\\@\\w+|\\#','', text) # remove mentions and hashtags\n",
        "    text = re.sub(r'\\d+', '', text) # remove numbers\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "def tokenize_text(text):\n",
        "    \"\"\"Tokenizes text into words.\"\"\"\n",
        "    if isinstance(text, str):\n",
        "        return nltk.word_tokenize(text)\n",
        "    return []\n",
        "\n",
        "def remove_stopwords(tokens):\n",
        "    \"\"\"Removes common stop words.\"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return [token for token in tokens if token not in stop_words]\n",
        "\n",
        "def lemmatize_text(tokens):\n",
        "    \"\"\"Reduces words to their base form using lemmatization.\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Combines all preprocessing steps.\"\"\"\n",
        "    cleaned_text = clean_text(text)\n",
        "    tokens = tokenize_text(cleaned_text)\n",
        "    filtered_tokens = remove_stopwords(tokens)\n",
        "    lemmatized_tokens = lemmatize_text(filtered_tokens)\n",
        "    return \" \".join(lemmatized_tokens)\n",
        "\n",
        "def preprocess_dataframe(df, text_column):\n",
        "    \"\"\"Applies preprocessing to a pandas DataFrame.\"\"\"\n",
        "    if text_column not in df.columns:\n",
        "        raise ValueError(f\"Column '{text_column}' not found in DataFrame.\")\n",
        "\n",
        "    df[\"processed_text\"] = df[text_column].apply(preprocess_text)\n",
        "    return df\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Example usage\n",
        "    try:\n",
        "        data = load_data(\"reviews.csv\")\n",
        "        if data is not None and not data.empty:\n",
        "            processed_df = preprocess_dataframe(data, \"text\") # Adjust \"text\" to your column name\n",
        "            print(processed_df.head())\n",
        "        else:\n",
        "            print(\"No data or an empty file was loaded. Please provide a csv file with reviews.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error during processing: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}