{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74BaeLIgH1IG"
      },
      "outputs": [],
      "source": [
        "# sentiment_models.py\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from textblob import TextBlob\n",
        "import numpy as np\n",
        "\n",
        "def train_naive_bayes(X_train, y_train, alpha=1.0):\n",
        "    \"\"\"Trains a Naive Bayes classifier.\"\"\"\n",
        "    model = MultinomialNB(alpha=alpha)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def train_logistic_regression(X_train, y_train, C=1.0, solver='liblinear', random_state=42):\n",
        "    \"\"\"Trains a Logistic Regression model.\"\"\"\n",
        "    model = LogisticRegression(C=C, solver=solver, random_state=random_state, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def train_random_forest(X_train, y_train, n_estimators=100, random_state=42):\n",
        "    \"\"\"Trains a Random Forest Classifier.\"\"\"\n",
        "    model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
        "    model.fit(X_train, y_train)\n",
        "    return model\n",
        "\n",
        "def train_svm(X_train, y_train, C=1.0, kernel='rbf', random_state=42):\n",
        "     \"\"\"Trains an SVM Classifier.\"\"\"\n",
        "     model = SVC(C=C, kernel=kernel, random_state=random_state)\n",
        "     model.fit(X_train, y_train)\n",
        "     return model\n",
        "\n",
        "def textblob_sentiment(text):\n",
        "    \"\"\"Performs sentiment analysis using TextBlob.\"\"\"\n",
        "    analysis = TextBlob(text)\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "      return \"positive\"\n",
        "    elif analysis.sentiment.polarity < 0:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "\n",
        "def grid_search(model_type, X_train, y_train, param_grid):\n",
        "  \"\"\"Performs Grid Search for Hyperparameter Tuning.\"\"\"\n",
        "  if model_type == \"naive_bayes\":\n",
        "      model = MultinomialNB()\n",
        "  elif model_type == \"logistic_regression\":\n",
        "       model = LogisticRegression(max_iter=1000)\n",
        "  elif model_type == \"random_forest\":\n",
        "        model = RandomForestClassifier(random_state=42)\n",
        "  elif model_type == \"svm\":\n",
        "        model = SVC(random_state=42)\n",
        "  else:\n",
        "       raise ValueError(f\"Unsupported model type {model_type} for hyperparameter tuning\")\n",
        "\n",
        "  grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "  grid_search.fit(X_train, y_train)\n",
        "  return grid_search.best_estimator_, grid_search.best_params_\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"Evaluates a model's performance.\"\"\"\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    return accuracy, report\n",
        "\n",
        "\n",
        "def main():\n",
        "     try:\n",
        "        import pandas as pd\n",
        "        from feature_engineering import create_tfidf_features, create_average_word_embeddings, split_data, create_word2vec_features\n",
        "        from data_preprocessing import preprocess_dataframe\n",
        "\n",
        "        data = pd.read_csv(\"reviews.csv\")\n",
        "        data.dropna(subset=[\"text\", \"sentiment\"], inplace=True)\n",
        "        processed_df = preprocess_dataframe(data, \"text\")\n",
        "        texts = processed_df[\"processed_text\"].tolist()\n",
        "        labels = processed_df[\"sentiment\"].tolist()\n",
        "\n",
        "        #TF-IDF\n",
        "        tfidf_matrix, tfidf_vectorizer = create_tfidf_features(texts)\n",
        "        X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = split_data(tfidf_matrix, labels)\n",
        "\n",
        "         #Average Word Embeddings\n",
        "        avg_embeddings = create_average_word_embeddings(texts)\n",
        "        X_train_avg_emb, X_test_avg_emb, y_train_avg_emb, y_test_avg_emb = split_data(avg_embeddings, labels)\n",
        "\n",
        "         #Word2Vec embeddings\n",
        "        word2vec_embeddings, word2vec_model = create_word2vec_features(texts)\n",
        "        X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = split_data(word2vec_embeddings, labels)\n",
        "\n",
        "        # -- Train and Evaluate Naive Bayes (TF-IDF) --\n",
        "        nb_model_tfidf = train_naive_bayes(X_train_tfidf.toarray(), y_train_tfidf)\n",
        "        accuracy_nb_tfidf, report_nb_tfidf = evaluate_model(nb_model_tfidf, X_test_tfidf.toarray(), y_test_tfidf)\n",
        "        print(\"Naive Bayes (TF-IDF) Accuracy:\", accuracy_nb_tfidf)\n",
        "        print(\"Naive Bayes (TF-IDF) Report:\\n\", report_nb_tfidf)\n",
        "\n",
        "        # -- Train and Evaluate Logistic Regression (TF-IDF) --\n",
        "        lr_model_tfidf = train_logistic_regression(X_train_tfidf.toarray(), y_train_tfidf)\n",
        "        accuracy_lr_tfidf, report_lr_tfidf = evaluate_model(lr_model_tfidf, X_test_tfidf.toarray(), y_test_tfidf)\n",
        "        print(\"Logistic Regression (TF-IDF) Accuracy:\", accuracy_lr_tfidf)\n",
        "        print(\"Logistic Regression (TF-IDF) Report:\\n\", report_lr_tfidf)\n",
        "\n",
        "        # --- Train and Evaluate Random Forest (TF-IDF) --\n",
        "        rf_model_tfidf = train_random_forest(X_train_tfidf.toarray(), y_train_tfidf)\n",
        "        accuracy_rf_tfidf, report_rf_tfidf = evaluate_model(rf_model_tfidf, X_test_tfidf.toarray(), y_test_tfidf)\n",
        "        print(\"Random Forest (TF-IDF) Accuracy:\", accuracy_rf_tfidf)\n",
        "        print(\"Random Forest (TF-IDF) Report:\\n\", report_rf_tfidf)\n",
        "\n",
        "        # --- Train and Evaluate SVM (TF-IDF)\n",
        "        svm_model_tfidf = train_svm(X_train_tfidf.toarray(), y_train_tfidf)\n",
        "        accuracy_svm_tfidf, report_svm_tfidf = evaluate_model(svm_model_tfidf, X_test_tfidf.toarray(), y_test_tfidf)\n",
        "        print(\"SVM (TF-IDF) Accuracy:\", accuracy_svm_tfidf)\n",
        "        print(\"SVM (TF-IDF) Report:\\n\", report_svm_tfidf)\n",
        "\n",
        "\n",
        "        # -- Train and Evaluate Naive Bayes (Avg Embeddings) --\n",
        "        nb_model_avg_emb = train_naive_bayes(X_train_avg_emb, y_train_avg_emb)\n",
        "        accuracy_nb_avg_emb, report_nb_avg_emb = evaluate_model(nb_model_avg_emb, X_test_avg_emb, y_test_avg_emb)\n",
        "        print(\"Naive Bayes (Avg. Embeddings) Accuracy:\", accuracy_nb_avg_emb)\n",
        "        print(\"Naive Bayes (Avg. Embeddings) Report:\\n\", report_nb_avg_emb)\n",
        "\n",
        "        # -- Train and Evaluate Logistic Regression (Avg Embeddings) --\n",
        "        lr_model_avg_emb = train_logistic_regression(X_train_avg_emb, y_train_avg_emb)\n",
        "        accuracy_lr_avg_emb, report_lr_avg_emb = evaluate_model(lr_model_avg_emb, X_test_avg_emb, y_test_avg_emb)\n",
        "        print(\"Logistic Regression (Avg. Embeddings) Accuracy:\", accuracy_lr_avg_emb)\n",
        "        print(\"Logistic Regression (Avg. Embeddings) Report:\\n\", report_lr_avg_emb)\n",
        "\n",
        "        # --- Train and Evaluate Random Forest (Avg Embeddings) --\n",
        "        rf_model_avg_emb = train_random_forest(X_train_avg_emb, y_train_avg_emb)\n",
        "        accuracy_rf_avg_emb, report_rf_avg_emb = evaluate_model(rf_model_avg_emb, X_test_avg_emb, y_test_avg_emb)\n",
        "        print(\"Random Forest (Avg. Embeddings) Accuracy:\", accuracy_rf_avg_emb)\n",
        "        print(\"Random Forest (Avg. Embeddings) Report:\\n\", report_rf_avg_emb)\n",
        "\n",
        "        # --- Train and Evaluate SVM (Avg Embeddings)\n",
        "        svm_model_avg_emb = train_svm(X_train_avg_emb, y_train_avg_emb)\n",
        "        accuracy_svm_avg_emb, report_svm_avg_emb = evaluate_model(svm_model_avg_emb, X_test_avg_emb, y_test_avg_emb)\n",
        "        print(\"SVM (Avg. Embeddings) Accuracy:\", accuracy_svm_avg_emb)\n",
        "        print(\"SVM (Avg. Embeddings) Report:\\n\", report_svm_avg_emb)\n",
        "\n",
        "        # --- Train and Evaluate Naive Bayes (Word2Vec) --\n",
        "        nb_model_w2v = train_naive_bayes(X_train_w2v, y_train_w2v)\n",
        "        accuracy_nb_w2v, report_nb_w2v = evaluate_model(nb_model_w2v, X_test_w2v, y_test_w2v)\n",
        "        print(\"Naive Bayes (Word2Vec) Accuracy:\", accuracy_nb_w2v)\n",
        "        print(\"Naive Bayes (Word2Vec) Report:\\n\", report_nb_w2v)\n",
        "\n",
        "        # -- Train and Evaluate Logistic Regression (Word2Vec) --\n",
        "        lr_model_w2v = train_logistic_regression(X_train_w2v, y_train_w2v)\n",
        "        accuracy_lr_w2v, report_lr_w2v = evaluate_model(lr_model_w2v, X_test_w2v, y_test_w2v)\n",
        "        print(\"Logistic Regression (Word2Vec) Accuracy:\", accuracy_lr_w2v)\n",
        "        print(\"Logistic Regression (Word2Vec) Report:\\n\", report_lr_w2v)\n",
        "\n",
        "        # --- Train and Evaluate Random Forest (Word2Vec) --\n",
        "        rf_model_w2v = train_random_forest(X_train_w2v, y_train_w2v)\n",
        "        accuracy_rf_w2v, report_rf_w2v = evaluate_model(rf_model_w2v, X_test_w2v, y_test_w2v)\n",
        "        print(\"Random Forest (Word2Vec) Accuracy:\", accuracy_rf_w2v)\n",
        "        print(\"Random Forest (Word2Vec) Report:\\n\", report_rf_w2v)\n",
        "\n",
        "        # --- Train and Evaluate SVM (Word2Vec)\n",
        "        svm_model_w2v = train_svm(X_train_w2v, y_train_w2v)\n",
        "        accuracy_svm_w2v, report_svm_w2v = evaluate_model(svm_model_w2v, X_test_w2v, y_test_w2v)\n",
        "        print(\"SVM (Word2Vec) Accuracy:\", accuracy_svm_w2v)\n",
        "        print(\"SVM (Word2Vec) Report:\\n\", report_svm_w2v)\n",
        "\n",
        "        # Example of TextBlob usage\n",
        "        example_text = \"This is a fantastic product! I am very happy.\"\n",
        "        textblob_result = textblob_sentiment(example_text)\n",
        "        print(f\"TextBlob sentiment of '{example_text}': {textblob_result}\")\n",
        "     except FileNotFoundError:\n",
        "          print(\"Error: 'reviews.csv' not found. Please provide the data in a 'reviews.csv' file with 'text' and 'sentiment' columns.\")\n",
        "     except KeyError as e:\n",
        "           print(f\"Error: {e} column not found. Ensure your 'reviews.csv' has 'text' and 'sentiment' columns.\")\n",
        "     except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ]
}